# Vector Database Integration Guide

This guide shows how to use the modular vector database adapters with your RAG system.

## ğŸ¯ Overview

Your RAG system now supports multiple vector database backends:
- **Qdrant** (current production database) âœ…
- **FAISS** (ultra-fast, local) âœ…
- **ChromaDB** (simple, embedded) âœ…
- **Pinecone** (future implementation)

All backends implement the same interface, making them **interchangeable**.

---

## ğŸ“¦ Installation

### Current Setup (Qdrant Only)
Your project works as-is with no changes needed!

### Add Optional Backends

```bash
# Install FAISS and ChromaDB
poetry install --with vector-db-extra

# Or separately:
poetry add --group vector-db-extra faiss-cpu
poetry add --group vector-db-extra chromadb
```

**Note**: These are **optional**. Your production code continues working without them.

---

## ğŸš€ Quick Start

### 1. Basic Usage (Standalone)

```python
from rag_llm_system.infrastructure.vector_stores import VectorStoreFactory
import numpy as np

# Create any backend
store = VectorStoreFactory.create("faiss")  # or "chroma", "qdrant"

# Use the same interface for all!
store.create_collection("my_articles", vector_size=384)
store.insert("my_articles", vectors=[...], metadata=[...])
results = store.search("my_articles", query_vector=[...], top_k=10)
```

### 2. Run Demo Scripts

```bash
# See FAISS in action
python -m examples.vector_db_comparison.demo_faiss

# See ChromaDB in action
python -m examples.vector_db_comparison.demo_chroma

# Compare all backends
python -m examples.vector_db_comparison.benchmark_comparison

# Simple usage example
python -m examples.vector_db_comparison.simple_usage_example
```

---

## ğŸ”§ Integration with Your RAG System

### Option 1: Keep Qdrant (Recommended)

**Do nothing!** Your production code continues to work exactly as before.

Use FAISS/ChromaDB only for:
- Learning and experimentation
- Development/testing
- Performance comparisons
- Offline deployments

---

### Option 2: Use Alternative Backend in New Code

If you want to try FAISS or ChromaDB in a **new feature**:

```python
# Example: Create a new experimental retriever
from rag_llm_system.infrastructure.vector_stores import VectorStoreFactory
from rag_llm_system.application.preprocessing.dispatchers import EmbeddingDispatcher

class ExperimentalRetriever:
    def __init__(self, backend="faiss"):
        # Use factory to create backend
        self.store = VectorStoreFactory.create(backend)
        self.collection = "experimental_articles"

    def index_documents(self, documents):
        # Same code works for any backend!
        vectors = []
        metadata = []

        for doc in documents:
            embedded = EmbeddingDispatcher.dispatch(doc)
            vectors.append(embedded.embedding)
            metadata.append({
                "author_id": str(doc.author_id),
                "content": doc.content[:200]
            })

        self.store.insert(
            self.collection,
            vectors=vectors,
            metadata=metadata
        )

    def search(self, query, top_k=10, author_filter=None):
        # Embed query
        embedded_query = EmbeddingDispatcher.dispatch(query)

        # Build filters
        filters = {"author_id": author_filter} if author_filter else None

        # Search (same interface for all backends!)
        results = self.store.search(
            self.collection,
            query_vector=embedded_query.embedding,
            top_k=top_k,
            filters=filters
        )

        return results
```

Usage:
```python
# Try FAISS
retriever_faiss = ExperimentalRetriever(backend="faiss")
retriever_faiss.index_documents(my_documents)
results = retriever_faiss.search("machine learning", top_k=10)

# Try ChromaDB
retriever_chroma = ExperimentalRetriever(backend="chroma")
retriever_chroma.index_documents(my_documents)
results = retriever_chroma.search("machine learning", top_k=10)
```

---

### Option 3: Environment-Based Backend Selection

Add backend selection via environment variable:

**1. Update `settings.py`:**

```python
# Add to your Settings class
class Settings(BaseSettings):
    # ... existing settings ...

    # Vector database selection
    VECTOR_DB_BACKEND: str = "qdrant"  # or "faiss", "chroma"
```

**2. Update `.env.example`:**

```bash
# Vector Database Backend (qdrant, faiss, chroma)
VECTOR_DB_BACKEND=qdrant
```

**3. Use in your code:**

```python
from rag_llm_system.settings import settings
from rag_llm_system.infrastructure.vector_stores import VectorStoreFactory

# Create backend from settings
store = VectorStoreFactory.create(settings.VECTOR_DB_BACKEND)

# Rest of your code unchanged!
```

Now you can switch backends by changing the environment variable!

---

### Option 4: A/B Testing (Compare Backends)

Run multiple backends side-by-side:

```python
from rag_llm_system.infrastructure.vector_stores import VectorStoreFactory

# Create multiple backends
qdrant = VectorStoreFactory.create("qdrant")
faiss = VectorStoreFactory.create("faiss")
chroma = VectorStoreFactory.create("chroma")

# Index same data in all backends
for store in [qdrant, faiss, chroma]:
    store.create_collection("test", vector_size=384)
    store.insert("test", vectors=vectors, metadata=metadata)

# Compare search results
query = generate_query_vector()

results_qdrant = qdrant.search("test", query, top_k=10)
results_faiss = faiss.search("test", query, top_k=10)
results_chroma = chroma.search("test", query, top_k=10)

# Analyze differences
compare_results(results_qdrant, results_faiss, results_chroma)
```

---

## ğŸ—ï¸ Architecture

### Current Project Structure

```
rag-llm-system/
â”œâ”€â”€ rag_llm_system/
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ qdrant.py           # EXISTING (unchanged)
â”‚   â”‚   â”‚   â””â”€â”€ mongo.py            # EXISTING (unchanged)
â”‚   â”‚   â””â”€â”€ vector_stores/          # NEW MODULE
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ base.py             # Abstract interface
â”‚   â”‚       â”œâ”€â”€ factory.py          # Factory pattern
â”‚   â”‚       â”œâ”€â”€ qdrant_adapter.py   # Wraps existing Qdrant
â”‚   â”‚       â”œâ”€â”€ faiss_adapter.py    # FAISS implementation
â”‚   â”‚       â””â”€â”€ chroma_adapter.py   # ChromaDB implementation
â”‚   â”‚
â”‚   â””â”€â”€ domain/
â”‚       â””â”€â”€ base/
â”‚           â””â”€â”€ vector.py           # EXISTING (unchanged)
â”‚
â””â”€â”€ examples/                        # NEW EXAMPLES
    â””â”€â”€ vector_db_comparison/
        â”œâ”€â”€ README.md
        â”œâ”€â”€ demo_faiss.py
        â”œâ”€â”€ demo_chroma.py
        â”œâ”€â”€ benchmark_comparison.py
        â””â”€â”€ simple_usage_example.py
```

**Key Points:**
- âœ… **No existing files modified**
- âœ… New code in separate module (`vector_stores/`)
- âœ… Examples in separate directory (`examples/`)
- âœ… Optional dependencies (won't break existing setup)

---

## ğŸ“ When to Use Each Backend

### Use Qdrant (Current) When:
- âœ… Production RAG system (your current use case)
- âœ… Need metadata filtering (author, date, category)
- âœ… Real-time updates (CRUD operations)
- âœ… Multi-collection support
- âœ… 1M-100M vectors

**Keep using Qdrant for your production system!**

---

### Use FAISS When:
- âš¡ Need **maximum speed** (10-100x faster)
- ğŸ’° Want to **save costs** at scale (billions of vectors)
- ğŸ“± Building **offline/edge** deployment
- ğŸ”¬ **Experimenting** with different algorithms
- ğŸ’» Simple filtering needs (post-filtering okay)

**Example Use Cases:**
- Prototyping RAG locally (no cloud)
- Deploying RAG to mobile/edge devices
- Research and algorithm comparison
- Demo applications

---

### Use ChromaDB When:
- ğŸš€ **Rapid prototyping**
- ğŸ‘¨â€ğŸ’» Python-first development
- ğŸ“¦ Small to medium datasets (<1M vectors)
- âœ… Need **simple API** and **auto-persistence**
- ğŸ” Excellent metadata filtering

**Example Use Cases:**
- Development environment
- Testing new RAG approaches
- Internal tools/demos
- LangChain projects

---

## ğŸ“Š Performance Comparison

Based on benchmarks (10K vectors, 384-dim):

| Backend   | Insert Speed | Search Time | Filtered Search | Metadata Support | Persistence |
|-----------|--------------|-------------|-----------------|------------------|-------------|
| **FAISS** | âš¡ 50K/s     | âš¡ 1-2ms    | ğŸŸ¡ 5-10ms       | ğŸŸ¡ Post-filter   | Manual      |
| **Chroma**| ğŸŸ¢ 5K/s      | ğŸŸ¢ 5-10ms   | âš¡ 10-20ms      | âœ… Native        | Automatic   |
| **Qdrant**| ğŸŸ¢ 10K/s     | ğŸŸ¢ 5-15ms   | ğŸŸ¢ 10-20ms      | âœ… Native        | Automatic   |

**Legend:**
- âš¡ = Excellent
- ğŸŸ¢ = Good
- ğŸŸ¡ = Okay (with caveats)

---

## ğŸ§ª Experimentation Workflow

### 1. Learn the Basics

```bash
# Run demos
python -m examples.vector_db_comparison.demo_faiss
python -m examples.vector_db_comparison.demo_chroma
```

### 2. Benchmark on Your Data

```bash
# Compare performance
python -m examples.vector_db_comparison.benchmark_comparison
```

### 3. Try in Your Code

```python
# Experiment with your actual embeddings
from rag_llm_system.infrastructure.vector_stores import VectorStoreFactory

faiss_store = VectorStoreFactory.create("faiss")
# ... use with your real data
```

### 4. Evaluate Results

- Compare search quality
- Measure latency differences
- Test filter performance
- Analyze cost implications

---

## ğŸ”’ Safety Guarantees

This module is **completely non-invasive**:

âœ… **No production code modified**
- Your Qdrant implementation unchanged
- RAG pipeline untouched
- Domain models unchanged

âœ… **Optional dependencies**
- Works without FAISS/ChromaDB installed
- Qdrant continues working independently

âœ… **Isolated examples**
- Demos in separate `examples/` directory
- Won't interfere with pipelines

âœ… **Easy to remove**
- Delete `vector_stores/` module
- Remove optional dependencies
- No side effects

**Your production system is safe!**

---

## ğŸ› ï¸ Advanced Topics

### Custom FAISS Indices

```python
from rag_llm_system.infrastructure.vector_stores.faiss_adapter import FAISSAdapter
import faiss

adapter = FAISSAdapter()

# Use HNSW for speed
index = faiss.IndexHNSWFlat(384, 32)
adapter.indices["my_collection"] = index

# Use IVF for memory efficiency
quantizer = faiss.IndexFlatL2(384)
index = faiss.IndexIVFFlat(quantizer, 384, 100)
adapter.indices["my_collection"] = index
```

### Hybrid Search (FAISS + MongoDB)

```python
# Use FAISS for vectors, MongoDB for metadata
from rag_llm_system.infrastructure.db.mongo import MongoDatabaseConnector
from rag_llm_system.infrastructure.vector_stores import VectorStoreFactory

# Vector search with FAISS
faiss_store = VectorStoreFactory.create("faiss")
vector_results = faiss_store.search("articles", query_vector, top_k=100)

# Filter by metadata in MongoDB
mongo = MongoDatabaseConnector()
filtered_ids = mongo.find({"author_id": "123"})

# Combine results
final_results = [r for r in vector_results if r.id in filtered_ids][:10]
```

---

## ğŸ“š Resources

- **FAISS**: [GitHub](https://github.com/facebookresearch/faiss) | [Paper](https://arxiv.org/abs/1702.08734)
- **ChromaDB**: [Docs](https://docs.trychroma.com/) | [GitHub](https://github.com/chroma-core/chroma)
- **Qdrant**: [Docs](https://qdrant.tech/documentation/) | [GitHub](https://github.com/qdrant/qdrant)
- **Vector DB Benchmarks**: [qdrant.tech/benchmarks](https://qdrant.tech/benchmarks/)

---

## â“ FAQ

**Q: Will this break my production code?**
A: No! This is a separate module with optional dependencies. Your Qdrant implementation is untouched.

**Q: Do I need to switch from Qdrant?**
A: No! Qdrant is excellent for your use case. This module is for learning and experimentation.

**Q: When should I use FAISS instead of Qdrant?**
A: For offline deployment, massive scale (billions of vectors), or when you need absolute maximum speed.

**Q: Can I delete this module later?**
A: Yes! Simply delete `rag_llm_system/infrastructure/vector_stores/` and remove the optional dependencies.

**Q: How do I check which backends are available?**
```python
from rag_llm_system.infrastructure.vector_stores import VectorStoreFactory
print(VectorStoreFactory.list_available_backends())
```

**Q: Can I use multiple backends simultaneously?**
A: Yes! Create multiple instances and use them side-by-side for comparison.

---

## ğŸš€ Next Steps

1. **Install dependencies**: `poetry install --with vector-db-extra`
2. **Run demos**: `python -m examples.vector_db_comparison.demo_faiss`
3. **Run benchmarks**: Compare performance on your hardware
4. **Experiment**: Try with your actual embeddings
5. **Learn**: Understand trade-offs between backends

---

**Happy experimenting! ğŸ‰**

For questions or issues, check:
- [examples/vector_db_comparison/README.md](examples/vector_db_comparison/README.md)
- FAISS/ChromaDB documentation
- Your project's existing Qdrant implementation
